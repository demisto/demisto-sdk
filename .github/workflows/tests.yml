name: Create and Publish Docker Image

on:
  workflow_call:
    inputs:
      test-type:
        required: true
        type: string
        description: "The type of the test that will run"
      node-version:
        required: false
        type: string
        default: "16"
        description: "The node version to install"
      ignored-file-paths:
        type: string
        required: false
        default: ""
        description: "A comma separated of file-paths to ignore when running tests"
      file-path:
        type: string
        required: false
        default: "."
        description: "The file path that from it tests will be executed"
      groups:
        type: string
        required: false
        default: "['All-Tests']"
        description: "The number of groups to split the tests into for concurrency"


jobs:
  tests:
    name: ${{inputs.test-type}} Tests / ${{ matrix.python-version }} (${{ matrix.group }})
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [ "3.8", "3.9", "3.10" ]
        group: ${{ fromJson(inputs.groups) }}
      fail-fast: false
    defaults:
      run:
        shell: bash
    steps:
      - uses: actions/checkout@v3
        with:
          fetch-depth: 0

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}

      - name: Setup Poetry
        run: |
          sudo curl -sSL https://install.python-poetry.org | python3 -
          poetry --version
          poetry check --lock
          poetry install -E generate-unit-tests

      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: ${{inputs.node-version}}

      - name: Install npm
        run: |
          npm install
          echo $(echo '{"node_version": "'$(node --version)'","npm_list":'$(npm list --json)'}') > node_versions_info.json

      - name: Run pytest
        run: |
          source "$(poetry env info --path)/bin/activate"

          # Due to race conditions in the tests bringing up and down the node server, have the server available
          # For all the tests.
          node demisto_sdk/commands/common/markdown_server/mdx-parse-server.js &
          node_pid=$!
          
          mkdir ${{inputs.test-type}}-test-results
          # poetry run pytest --ignore={demisto_sdk/commands/init/templates,demisto_sdk/tests/integration_tests} --store-durations --junitxml=${{inputs.test-type}}-test-results/junit.xml || pytest_exit_code=$
          # mv .test_durations test-results/test_durations
             
          echo "ignored-file-paths=${{ inputs.ignored-file-paths }}, file-path=${{ inputs.file-path }}"
          if [[ "${my_array[@]}" = "All-Tests" ]]; then
            echo "Running "${{ inputs.test-type }} tests without splitting"
            poetry run pytest -v "${{ inputs.file-path }}" --ignore={"${{ inputs.ignored-file-paths }}"} --cov=demisto_sdk --cov-report=html --junitxml="${{ inputs.test-type }}-test-results/junit.xml" || pytest_exit_code=$?
          else
            echo "Running "${{ inputs.test-type }} tests without splitting the tests"
            input_groups=${{ fromJson(inputs.groups) }}
            splits=${#input_groups[@]}
            poetry run pytest -v "${{ inputs.file-path }}" --ignore={"${{ inputs.ignored-file-paths }}"} --cov=demisto_sdk --cov-report=html --junitxml="${{ inputs.test-type }}-test-results/junit.xml" --splits "${splits}" --group "${{ matrix.group }}" || pytest_exit_code=$?
          fi
          echo "PYTEST_EXIT_CODE=$pytest_exit_code" >> $GITHUB_ENV
          kill $node_pid
      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: ${{ inputs.test-type }}-tests-artifacts-${{ matrix.python-version }}-group-${{ matrix.group }}
          path: |
            .test_durations
            ${{ inputs.test-type }}-test-results/junit.xml
            node_versions_info.json
            coverage_html_report
            .coverage
      - name: Print Summary of pytest results in workflow summary
        if: always()
        uses: pmeier/pytest-results-action@main
        with:
          path: ${{ inputs.test-type }}-test-results/junit.xml
          summary: true
          display-options: fsEX
          fail-on-empty: true
      - name: Check if ${{ inputs.test-type }}-tests have passed
        if: always()
        run: |
          if [[ "$PYTEST_EXIT_CODE" -ne 0 ]]; then
            echo "There are ${{ inputs.test-type }}-tests that failed, pytest finished with exit code $PYTEST_EXIT_CODE, to see the tests summary refer to https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}?pr=${{ github.event.pull_request.number }}"
          else
            echo "All ${{ inputs.test-type }}-tests have passed, congratulations!"
          fi
          exit $PYTEST_EXIT_CODE